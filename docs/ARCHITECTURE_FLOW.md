# Fleet Compliance Agent - Architecture & Flow Diagrams

This document provides visual and technical documentation of the Fleet Compliance Agent's **agentic architecture** where the GitHub Copilot SDK acts as the autonomous decision-making brain.

---

## Core Concept: SDK as Agent Brain

The Fleet Compliance Agent is a **TRUE agentic implementation**:
- The Copilot SDK decides which tools to call and in what order
- Custom tools are registered with the SDK and exposed via function calling
- The SDK reasons about tool results and decides next steps
- The agent loop continues until the task is complete

```mermaid
flowchart TB
    subgraph AgentBrain["ğŸ§  Copilot SDK - The Agent Brain"]
        LLM[GPT-4o<br/>via Copilot API]
        PROMPT[System Prompt<br/>Compliance Workflow Instructions]
        DECIDE[/"Autonomous Decision Making<br/>Which tool? What args?"/]
    end

    subgraph CustomTools["ğŸ”§ 11 Custom Tools"]
        T1[rag_search]
        T2[clone_repository]
        T3[detect_compliance_drift]
        T4[security_scan]
        T5[create_branch]
        T6[apply_compliance_patches]
        T7[get_required_approvals]
        T8[run_tests]
        T9[commit_changes]
        T10[push_branch]
        T11[create_pull_request]
    end

    subgraph External["ğŸŒ External Services"]
        AOAI[(Azure OpenAI<br/>Vector Store)]
        MCP_SEC[MCP: Security Server]
        MCP_CM[MCP: Change Mgmt Server]
        GH[(GitHub)]
    end

    LLM --> DECIDE
    PROMPT --> LLM
    DECIDE -->|function call| T1 & T2 & T3 & T4 & T5 & T6 & T7 & T8 & T9 & T10 & T11
    
    T1 -->|results| LLM
    T2 -->|results| LLM
    T3 -->|results| LLM
    
    T1 --> AOAI
    T4 --> MCP_SEC
    T7 --> MCP_CM
    T2 & T9 & T10 & T11 --> GH

    style AgentBrain fill:#9944ff,color:white
    style LLM fill:#6633cc,color:white
```

---

## Agent Loop Sequence

```mermaid
sequenceDiagram
    participant User
    participant AgentLoop as Agent Loop
    participant SDK as Copilot SDK
    participant Tools as Custom Tools
    participant External as External Services

    User->>AgentLoop: Process repositories
    AgentLoop->>SDK: Create session with 11 tools
    AgentLoop->>SDK: Send user prompt
    
    loop Until session.idle
        SDK->>SDK: Reason about task
        SDK-->>AgentLoop: tool.execution_start
        AgentLoop->>Tools: Invoke handler
        Tools->>External: (RAG/MCP/Git)
        External-->>Tools: Response
        Tools-->>AgentLoop: ToolResult
        AgentLoop-->>SDK: Tool result
        SDK->>SDK: Reason about result
        SDK-->>AgentLoop: assistant.message
    end
    
    SDK-->>AgentLoop: session.idle
    AgentLoop-->>User: Summary with PRs
```

---

## Simple Flow Diagram (Agentic Mode)

```mermaid
flowchart TB
    subgraph SDK["ğŸ§  Copilot SDK - Agent Brain"]
        LLM[GPT-4o decides<br/>which tools to call]
    end

    subgraph Tools["ğŸ”§ Custom Tool Flow"]
        A[rag_search] --> B[clone_repository]
        B --> C[detect_compliance_drift]
        C --> D[security_scan]
        D --> E[create_branch]
        E --> F[apply_compliance_patches]
        F --> G[get_required_approvals]
        G --> H[run_tests]
        H --> I[commit_changes]
        I --> J[push_branch]
        J --> K[create_pull_request]
    end

    subgraph External["ğŸŒ External Services"]
        RAG[(Azure OpenAI<br/>Vector Store)]
        MCP[(MCP Servers)]
        GH[(GitHub)]
    end

    LLM -->|function calling| Tools
    Tools -->|results| LLM
    
    A --> RAG
    D & G --> MCP
    B & I & J & K --> GH

    style SDK fill:#9944ff,color:white
    style LLM fill:#6633cc,color:white
    style A fill:#4a9eff,color:white
    style D fill:#ff9944,color:white
    style G fill:#ff9944,color:white
```

---

## Tool Registration (agent_loop.py)

The agentic implementation registers 11 custom tools with the Copilot SDK:

```python
from copilot import CopilotClient
from copilot.types import Tool, ToolResult

# Create tool with handler and JSON Schema parameters
rag_search_tool = Tool(
    name="rag_search",
    description="Search the knowledge base for compliance policy documents.",
    handler=rag_search_handler,  # Function that returns ToolResult
    parameters={
        "type": "object",
        "properties": {
            "query": {"type": "string", "description": "Search query"}
        },
        "required": ["query"]
    }
)

# Session with ONLY custom tools (available_tools whitelist)
session = await client.create_session({
    "model": "gpt-4o",
    "system_message": {"content": SYSTEM_PROMPT},
    "tools": [rag_search_tool, clone_tool, ...],
    "available_tools": ["rag_search", "clone_repository", ...]  # Whitelist
})
```

**Key Pattern**: Use `available_tools` (not `excluded_tools`) to ensure the SDK only uses custom tools, not built-in ones.

---

## Comprehensive Flow Diagram (Legacy Reference)

```mermaid
flowchart TB
    subgraph Config["ğŸ“‹ Configuration & State"]
        CFG[repos.json<br/>3 FastAPI repos]
        ENV[.env<br/>USE_COPILOT_SDK=true<br/>PYTEST_ENABLED=true]
        KNOWLEDGE[knowledge/<br/>6 policy documents]
    end

    subgraph Init["ğŸš€ Initialization - Run Once"]
        START([Agent Start]) --> TRACKER[Initialize Progress Tracker<br/>run_id, start_time]
        TRACKER --> AUTH[gh auth status<br/>Verify GitHub CLI]
        AUTH --> LOAD[Load repos.json<br/>â†’ 3 repositories]
    end

    subgraph RAG["ğŸ” RAG - Azure OpenAI Vector Store Only"]
        direction TB
        LOAD --> QUERY[Build Query:<br/>'structured logging trace propagation<br/>health readiness approval vulnerability']
        QUERY --> AOAI[(Azure OpenAI<br/>Responses API)]
        AOAI --> VS[(Vector Store<br/>vs_VdxnOBxS...)]
        VS --> EMBED[Embedding Model<br/>text-embedding-3-small]
        EMBED --> SIM[Cosine Similarity<br/>k=4 results]
        SIM --> HITS[Policy Evidence<br/>4 documents returned]
        
        NOTE1[/"âš ï¸ Azure OpenAI used ONLY<br/>for Vector Store, NOT LLM"/]
    end

    subgraph RepoLoop["ğŸ”„ Repository Loop - Sequential Processing"]
        direction TB
        HITS --> FOREACH{{"for repo in repos"}}
        
        FOREACH --> CLONE[Clone Repository<br/>â†’ workspaces/service-xxxx/]
        CLONE --> DETECT[Detect Drift<br/>patcher_fastapi.detect()]
        
        DETECT --> DRIFT_CHECK{Missing:<br/>healthz? readyz?<br/>structlog? middleware?}
        DRIFT_CHECK -->|None Missing| SKIP_REPO[Skip: No drift]
        
        DRIFT_CHECK -->|Has Drift| SEC_SCAN[MCP: Security Scan<br/>Port 4102]
        SEC_SCAN --> SEC_REQ[POST /scan<br/>requirements.txt content]
        SEC_REQ --> SEC_RESP[Response: CVE findings]
        
        SEC_RESP --> BRANCH[Create Feature Branch<br/>chore/fleet-compliance-xxx]
        BRANCH --> PATCH[Apply Patches<br/>patcher_fastapi.apply()]
        
        PATCH --> PATCH_DETAIL[/"Creates/Modifies:<br/>â€¢ app/logging_config.py<br/>â€¢ app/middleware.py<br/>â€¢ app/main.py<br/>â€¢ requirements.txt<br/>â€¢ tests/test_health.py"/]
        
        PATCH_DETAIL --> APPROVAL[MCP: Approval Routing<br/>Port 4101]
        APPROVAL --> APPR_REQ[POST /approval<br/>service, touched_paths]
        APPR_REQ --> APPR_RESP[Response: required_approvals<br/>ServiceOwner, SRE-Prod, Security]
        
        APPR_RESP --> TEST_CHECK{tests/ exists<br/>& PYTEST_ENABLED?}
        TEST_CHECK -->|No| SKIP_TEST[Skip Tests]
        TEST_CHECK -->|Yes| PYTEST[pip install -r requirements.txt<br/>python -m pytest -q]
        
        PYTEST --> TEST_RESULT{Tests Pass?}
        TEST_RESULT -->|Pass| COMMIT[Git Commit]
        TEST_RESULT -->|Fail| COMMIT_ANYWAY[Commit Anyway<br/>Note failure in PR]
        SKIP_TEST --> COMMIT
        
        COMMIT --> PUSH[Git Push Branch]
        COMMIT_ANYWAY --> PUSH
    end

    subgraph CopilotSDK["ğŸ¤– GitHub Copilot SDK - Streaming"]
        direction TB
        PUSH --> SDK_CHECK{USE_COPILOT_SDK?}
        SDK_CHECK -->|false| TEMPLATE[Deterministic Template<br/>Pre-built PR body]
        
        SDK_CHECK -->|true| SDK_INIT[Initialize CopilotClient<br/>COPILOT_CLI_PATH â†’ copilot.cmd]
        SDK_INIT --> SESSION[Create Session<br/>model: gpt-4o<br/>system_message: PR assistant]
        
        SESSION --> PROMPT[Build Prompt:<br/>â€¢ Instruction text<br/>â€¢ Policy evidence from RAG<br/>â€¢ Changed files list<br/>â€¢ Output format spec]
        
        PROMPT --> SEND[session.send prompt]
        
        SEND --> EVENTS{{"Event Loop<br/>session.on event_handler"}}
        
        EVENTS --> |assistant.message.delta| STREAM[Stream Tokens<br/>print chunk, flush=True]
        STREAM --> COLLECT[Append to response_chunks]
        COLLECT --> EVENTS
        
        EVENTS --> |assistant.message| FULL[Full Message Event<br/>Append if non-empty content]
        FULL --> COLLECT
        
        EVENTS --> |session.idle| DONE[Set done.set]
        EVENTS --> |error| ERR[Log Error, done.set]
        
        DONE --> COMBINE[Combine Chunks<br/>full_response = ''.join chunks]
        ERR --> FALLBACK[CLI Fallback<br/>gh copilot suggest]
        
        COMBINE --> CREATE_PR
        FALLBACK --> CREATE_PR
        TEMPLATE --> CREATE_PR
    end

    subgraph GitHub["ğŸ™ GitHub PR Creation"]
        CREATE_PR[Build PR:<br/>title, body, labels] --> GH_API[gh pr create<br/>--base main<br/>--head branch<br/>--title --body]
        GH_API --> LABELS{Approval Labels}
        LABELS -->|SRE-Prod required| LABEL_SRE[Add: needs-sre-approval]
        LABELS -->|Security required| LABEL_SEC[Add: needs-security-approval]
        LABEL_SRE --> PR_CREATED
        LABEL_SEC --> PR_CREATED
        LABELS -->|Only ServiceOwner| PR_CREATED[PR Created âœ…]
    end

    subgraph NextOrEnd["â­ï¸ Loop Control"]
        PR_CREATED --> MORE{More repos?}
        SKIP_REPO --> MORE
        MORE -->|Yes| FOREACH
        MORE -->|No| SUMMARY[Print Run Summary<br/>Duration, Steps, Calls]
    end

    CFG -.-> LOAD
    ENV -.-> AUTH
    ENV -.-> SDK_CHECK
    KNOWLEDGE -.-> VS

    style AOAI fill:#4a9eff,color:white
    style VS fill:#4a9eff,color:white
    style SEC_SCAN fill:#ff9944,color:white
    style APPROVAL fill:#ff9944,color:white
    style SDK_INIT fill:#9944ff,color:white
    style SESSION fill:#9944ff,color:white
    style EVENTS fill:#9944ff,color:white
```

---

## State & Memory Handling

```mermaid
stateDiagram-v2
    [*] --> Initialized: Load .env, repos.json
    
    Initialized --> RAGComplete: Vector search (1x)
    
    state "Per-Repo State (Ephemeral)" as PerRepo {
        RAGComplete --> Cloned: Clone to workspace
        Cloned --> DriftDetected: Analyze main.py
        DriftDetected --> Scanned: MCP security scan
        Scanned --> Patched: Apply fixes
        Patched --> Tested: Run pytest
        Tested --> Committed: Git commit
        Committed --> PRCreated: Push + PR
    }
    
    PRCreated --> RAGComplete: Next repo (reuse evidence)
    PRCreated --> Summary: All repos done
    
    Summary --> [*]: Print results
    
    note right of Initialized
        Global State (persisted across repos):
        â€¢ evidence: str (RAG results)
        â€¢ tracker: ProgressTracker
        â€¢ use_copilot: bool
        â€¢ pytest_enabled: bool
    end note
    
    note right of PerRepo
        Per-Repo State (reset each iteration):
        â€¢ ws: Path (workspace dir)
        â€¢ drift: Drift dataclass
        â€¢ sec: dict (CVE findings)
        â€¢ touched: list[str] (modified files)
        â€¢ branch: str
        â€¢ body: str (PR description)
        â€¢ labels: list[str]
    end note
```

---

## Key Architecture Points

### 1. Loop Structure: Sequential Per-Repository

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTER LOOP: for url in repos (sequential)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  INNER EXECUTION: All steps for ONE repo (synchronous)    â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Clone â†’ Detect â†’ Scan â†’ Patch â†’ Test â†’ Commit â†’ PR      â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  NO inner loop per tool call - each step runs once        â”‚  â”‚
â”‚  â”‚  Agent controls flow, detects completion, moves to next   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The agent is NOT agentic/autonomous per tool call** - it follows a deterministic workflow:
1. Each repository is processed **sequentially** (not in parallel)
2. Within a repo, each step executes **exactly once** in order
3. The workflow code (`run.py`) explicitly controls when to proceed to the next step
4. No LLM decides "what to do next" - the steps are hard-coded
5. The only "intelligence" is in the **patcher** (detecting drift patterns) and **Copilot SDK** (generating PR text)

### 2. Azure OpenAI: Vector Store Only (NOT LLM)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Azure OpenAI Service                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   âœ… USED: Vector Store                                   â”‚  â”‚
â”‚  â”‚   â€¢ Endpoint: sansri-foundry-hosted-agents-pro.openai... â”‚  â”‚
â”‚  â”‚   â€¢ Vector Store ID: vs_VdxnOBxSZXafnJSjR0g7JBBE         â”‚  â”‚
â”‚  â”‚   â€¢ Embedding Model: text-embedding-3-small              â”‚  â”‚
â”‚  â”‚   â€¢ Responses API with file_search tool                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   âŒ NOT USED: LLM Models (gpt-4o, etc.)                  â”‚  â”‚
â”‚  â”‚   â€¢ No chat completions from Azure OpenAI                â”‚  â”‚
â”‚  â”‚   â€¢ LLM capability comes from GitHub Copilot SDK         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. GitHub Copilot SDK Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Copilot SDK (github-copilot-sdk)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚  Prerequisites:                                                    â”‚
â”‚  â€¢ COPILOT_CLI_PATH â†’ C:\Users\...\npm\copilot.cmd (Windows)      â”‚
â”‚  â€¢ GitHub CLI authenticated (gh auth login)                        â”‚
â”‚  â€¢ Copilot CLI extension (gh extension install github/gh-copilot) â”‚
â”‚                                                                    â”‚
â”‚  How it works:                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    JSON-RPC    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     API     â”Œâ”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Python   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Copilot CLI â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚GitHubâ”‚ â”‚
â”‚  â”‚ SDK      â”‚                â”‚ (server     â”‚             â”‚Copilotâ”‚â”‚
â”‚  â”‚          â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  mode)      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ API   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   SSE Events   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                    â”‚
â”‚  Streaming Implementation:                                         â”‚
â”‚  â€¢ CopilotClient.start() launches CLI in server mode              â”‚
â”‚  â€¢ create_session() initializes with model + system prompt        â”‚
â”‚  â€¢ session.on(handler) registers event callback                   â”‚
â”‚  â€¢ session.send(prompt) sends user message                        â”‚
â”‚  â€¢ Events: assistant.message.delta (tokens), assistant.message    â”‚
â”‚  â€¢ Chunks collected â†’ joined â†’ returned as CopilotDraft           â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Streaming Response Handling

```python
# Simplified event handler from copilot_assist.py

def on_event(event):
    event_type = event.type.value
    
    # Option 1: Streaming deltas (tokens as they arrive)
    if event_type in ("assistant.message.delta", "content.delta"):
        chunk = event.data.delta or event.data.content
        response_chunks.append(chunk)
        print(chunk, end="", flush=True)  # Real-time output
    
    # Option 2: Complete message (batched response)
    elif event_type == "assistant.message":
        if event.data.content and len(event.data.content) > 0:
            response_chunks.append(event.data.content)
    
    # Completion signal
    elif event_type == "session.idle":
        done.set()  # Unblock wait

# After all events:
full_response = "".join(response_chunks)
```

### 5. MCP Server Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP Servers (Model Context Protocol)                           â”‚
â”‚  Local FastAPI services providing domain-specific tools         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Security Scanner (Port 4102)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  POST /scan                                                â”‚ â”‚
â”‚  â”‚  Input:  { "requirements": "fastapi==0.100.0\n..." }      â”‚ â”‚
â”‚  â”‚  Output: { "findings": [ { "package": "pyjwt",            â”‚ â”‚
â”‚  â”‚                           "cve": "CVE-2024-...",           â”‚ â”‚
â”‚  â”‚                           "severity": "high" } ] }         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  Change Management (Port 4101)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  POST /approval                                            â”‚ â”‚
â”‚  â”‚  Input:  { "service": "contoso-payments-api",             â”‚ â”‚
â”‚  â”‚            "touched_paths": ["app/auth.py"] }              â”‚ â”‚
â”‚  â”‚  Output: { "required_approvals": ["SRE-Prod","Security"], â”‚ â”‚
â”‚  â”‚            "risk_level": "high",                           â”‚ â”‚
â”‚  â”‚            "rationale": "High-impact + sensitive files" }  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6. PR Generation Instruction

The prompt sent to Copilot SDK includes:

```markdown
## Instruction
Write a PR description for a fleet compliance remediation PR. 
Include risk and rollout suggestions.

## Policy Evidence (from knowledge base)
- **OPS-2.1-health-readiness.md**: Health and readiness endpoints 
  are required for all HTTP services deployed on Kubernetes...
- **SEC-2.4-dependency-vulnerability-response.md**: All dependencies 
  must be scanned for CVEs. Critical vulnerabilities must be...
[... 2 more documents ...]

## Changes Made
- app/main.py
- app/middleware.py
- app/logging_config.py
- requirements.txt
- tests/test_health.py

## Output Format
Please provide a professional PR description with:
1. **Summary** - Brief overview of the changes
2. **Changes** - Bullet list of specific modifications
3. **Policy Compliance** - How this addresses fleet policies
4. **Risk Assessment** - Any deployment considerations
5. **Testing** - Verification steps performed
```

### 7. Test Execution & Error Handling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Unit Test Execution (per-repository)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Prerequisites:                                                 â”‚
â”‚  â€¢ PYTEST_ENABLED=true in .env                                  â”‚
â”‚  â€¢ tests/ directory exists in repository                        â”‚
â”‚                                                                 â”‚
â”‚  Execution Flow:                                                â”‚
â”‚  1. pip install -r requirements.txt (install dependencies)     â”‚
â”‚  2. python -m pytest -q (run tests quietly)                    â”‚
â”‚                                                                 â”‚
â”‚  Error Handling:                                                â”‚
â”‚  â€¢ Tests PASS  â†’ Continue to commit/push/PR                    â”‚
â”‚  â€¢ Tests FAIL  â†’ Log failure, STILL create PR (human review)   â”‚
â”‚  â€¢ Tests ERROR â†’ Catch exception, continue with PR             â”‚
â”‚                                                                 â”‚
â”‚  Why not block on failures?                                     â”‚
â”‚  â€¢ Agent patches are deterministic and tested                  â”‚
â”‚  â€¢ Existing repo tests may fail for unrelated reasons          â”‚
â”‚  â€¢ Human reviewers see test status and decide                  â”‚
â”‚  â€¢ Better to surface issue in PR than silently skip            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Complete Data Flow

```mermaid
sequenceDiagram
    autonumber
    participant Agent as Fleet Agent<br/>(run.py)
    participant RAG as Azure OpenAI<br/>Vector Store
    participant MCP_Sec as MCP Security<br/>:4102
    participant MCP_CM as MCP Change Mgmt<br/>:4101
    participant Copilot as GitHub Copilot<br/>SDK
    participant GH as GitHub API

    Note over Agent: ğŸš€ Initialization (once)
    Agent->>Agent: Load repos.json (3 repos)
    Agent->>GH: gh auth status
    GH-->>Agent: Authenticated âœ“
    
    Agent->>RAG: search("structured logging health...")
    RAG-->>Agent: 4 policy documents (evidence)
    
    Note over Agent: ğŸ”„ Loop: contoso-orders-api
    Agent->>GH: git clone
    Agent->>Agent: detect() â†’ missing_healthz=true
    Agent->>MCP_Sec: POST /scan (requirements.txt)
    MCP_Sec-->>Agent: {findings: []}
    Agent->>Agent: apply() â†’ 5 files patched
    Agent->>MCP_CM: POST /approval (service, paths)
    MCP_CM-->>Agent: {required: [ServiceOwner]}
    Agent->>Agent: pytest â†’ PASS âœ“
    Agent->>GH: git push branch
    
    Agent->>Copilot: session.send(prompt + evidence)
    loop Streaming Events
        Copilot-->>Agent: assistant.message.delta (token)
        Agent->>Agent: print(token, flush=True)
    end
    Copilot-->>Agent: session.idle
    Agent->>Agent: join chunks â†’ PR body
    
    Agent->>GH: gh pr create (title, body, labels)
    GH-->>Agent: PR #9 created âœ“
    
    Note over Agent: ğŸ”„ Loop: contoso-payments-api
    Agent->>GH: git clone
    Agent->>Agent: detect() â†’ missing_healthz=true
    Agent->>MCP_Sec: POST /scan
    MCP_Sec-->>Agent: {findings: [2 CVEs]}
    Agent->>Agent: apply() â†’ 5 files patched
    Agent->>MCP_CM: POST /approval
    MCP_CM-->>Agent: {required: [SRE-Prod,Security]}
    Agent->>Agent: pytest â†’ PASS âœ“
    Agent->>GH: git push branch
    Agent->>Copilot: session.send(prompt)
    Copilot-->>Agent: 2385 chars generated
    Agent->>GH: gh pr create + labels
    GH-->>Agent: PR #8 created âœ“
    
    Note over Agent: ğŸ”„ Loop: contoso-catalog-api
    Agent->>GH: git clone ... (same pattern)
    
    Note over Agent: âœ… Summary
    Agent->>Agent: Print run stats
```

---

## Summary Table

| Aspect | Implementation |
|--------|----------------|
| **Loop Structure** | Sequential per-repo, synchronous per-step |
| **Tool Autonomy** | No - workflow is deterministic, not LLM-driven |
| **State Persistence** | Global: evidence, settings. Per-repo: workspace, drift, branch |
| **Memory** | No long-term memory; fresh workspace each run |
| **Azure OpenAI** | Vector Store ONLY (file_search), NOT LLM |
| **LLM Provider** | GitHub Copilot SDK via Copilot CLI |
| **Streaming** | Event-based: delta tokens â†’ chunks â†’ joined response |
| **Error Handling** | Tests can fail, PR still created (human decides) |
| **Completion Detection** | Explicit loop control, not LLM judgment |

